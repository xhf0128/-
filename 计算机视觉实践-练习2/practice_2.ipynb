{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # input(3,28,28) output(6,24,24)\n",
    "        x = self.pool1(x)           # output(6,12,12)\n",
    "        x = F.relu(self.conv2(x))   # output(16,8,8)\n",
    "        x = self.pool2(x)           # output(16,4,4)\n",
    "        # print(x.size())\n",
    "        x = x.view(-1, 16 * 4 * 4)  # output(4*4*16)\n",
    "        x = F.relu(self.fc1(x))     # output(120)\n",
    "        x = F.relu(self.fc2(x))     # output(84)\n",
    "        x = self.fc3(x)             # output(10)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.Size([5000, 3, 28, 28])\n",
      "[1,   500] train_loss: 2.108  test_accuracy: 0.949\n",
      "[1,  1000] train_loss: 0.558  test_accuracy: 0.968\n",
      "[1,  1500] train_loss: 0.519  test_accuracy: 0.977\n",
      "[2,   500] train_loss: 0.371  test_accuracy: 0.973\n",
      "[2,  1000] train_loss: 0.284  test_accuracy: 0.976\n",
      "[2,  1500] train_loss: 0.324  test_accuracy: 0.980\n",
      "[3,   500] train_loss: 0.251  test_accuracy: 0.978\n",
      "[3,  1000] train_loss: 0.199  test_accuracy: 0.978\n",
      "[3,  1500] train_loss: 0.265  test_accuracy: 0.981\n",
      "[4,   500] train_loss: 0.182  test_accuracy: 0.978\n",
      "[4,  1000] train_loss: 0.172  test_accuracy: 0.982\n",
      "[4,  1500] train_loss: 0.208  test_accuracy: 0.982\n",
      "[5,   500] train_loss: 0.148  test_accuracy: 0.980\n",
      "[5,  1000] train_loss: 0.126  test_accuracy: 0.981\n",
      "[5,  1500] train_loss: 0.175  test_accuracy: 0.983\n",
      "[6,   500] train_loss: 0.112  test_accuracy: 0.981\n",
      "[6,  1000] train_loss: 0.111  test_accuracy: 0.980\n",
      "[6,  1500] train_loss: 0.144  test_accuracy: 0.981\n",
      "[7,   500] train_loss: 0.112  test_accuracy: 0.979\n",
      "[7,  1000] train_loss: 0.118  test_accuracy: 0.986\n",
      "[7,  1500] train_loss: 0.129  test_accuracy: 0.981\n",
      "[8,   500] train_loss: 0.094  test_accuracy: 0.982\n",
      "[8,  1000] train_loss: 0.087  test_accuracy: 0.982\n",
      "[8,  1500] train_loss: 0.120  test_accuracy: 0.982\n",
      "[9,   500] train_loss: 0.086  test_accuracy: 0.984\n",
      "[9,  1000] train_loss: 0.091  test_accuracy: 0.986\n",
      "[9,  1500] train_loss: 0.098  test_accuracy: 0.977\n",
      "[10,   500] train_loss: 0.076  test_accuracy: 0.986\n",
      "[10,  1000] train_loss: 0.063  test_accuracy: 0.980\n",
      "[10,  1500] train_loss: 0.089  test_accuracy: 0.982\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# device : GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=36,\n",
    "                                           shuffle=False, num_workers=0)\n",
    "val_set = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=5000,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "val_data_iter = iter(val_loader)\n",
    "val_image, val_label = val_data_iter.next()\n",
    "print(val_image.size())\n",
    "\n",
    "net = LeNet()\n",
    "net.to(device)\n",
    "# 损失函数\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0 #累加损失\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs.size(), labels.size())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # 如果不清除历史梯度，就会对计算的历史梯度进行累加\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.to(device))\n",
    "        loss = loss_function(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if step % 500 == 499:    # print every 500 mini-batches\n",
    "            with torch.no_grad():\n",
    "                outputs = net(val_image.to(device))  # [batch, 10]\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                accuracy = (predict_y == val_label.to(device)).sum().item() / val_label.size(0)\n",
    "\n",
    "                print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %\n",
    "                      (epoch + 1, step + 1, running_loss / 100, accuracy))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "save_path = '../model/Lenet.pth'\n",
    "torch.save(net.state_dict(), save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:0.9890000224113464\n"
     ]
    }
   ],
   "source": [
    "test_set = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10000,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "test_data = next(iter(test_loader))\n",
    "\n",
    "net = LeNet()\n",
    "net.load_state_dict(torch.load('../model/lenet.pth'))\n",
    "with torch.no_grad():\n",
    "    x,y = test_data[0],test_data[1]\n",
    "    output = net(x)\n",
    "    pred = torch.max(output,1)[1]\n",
    "    print(f'test acc:{sum(pred==y)/output.shape[0]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
